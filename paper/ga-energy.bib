@article{menghani2023efficient,
author = {Menghani, Gaurav},
title = {Efficient Deep Learning: A Survey on Making Deep Learning Models Smaller, Faster, and Better},
year = {2023},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {12},
issn = {0360-0300},
url = {https://doi.org/10.1145/3578938},
doi = {10.1145/3578938},
abstract = {Deep learning has revolutionized the fields of computer vision, natural language understanding, speech recognition, information retrieval, and more. However, with the progressive improvements in deep learning models, their number of parameters, latency, and resources required to train, among others, have all increased significantly. Consequently, it has become important to pay attention to these footprint metrics of a model as well, not just its quality. We present and motivate the problem of efficiency in deep learning, followed by a thorough survey of the five core areas of model efficiency (spanning modeling techniques, infrastructure, and hardware) and the seminal work there. We also present an experiment-based guide along with code for practitioners to optimize their model training and deployment. We believe this is the first comprehensive survey in the efficient deep learning space that covers the landscape of model efficiency from modeling techniques to hardware support. It is our hope that this survey would provide readers with the mental model and the necessary understanding of the field to apply generic efficiency techniques to immediately get significant improvements, and also equip them with ideas for further research and experimentation to achieve additional gains.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {259},
numpages = {37},
keywords = {Efficient deep learning, efficient machine learning, efficient artificial intelligence, quantization, pruning, sparsity, distillation, model compression, model optimization}
}

@inproceedings{alizadeh2024green,
  title={Green AI: A Preliminary Empirical Study on Energy Consumption in DL Models Across Different Runtime Infrastructures},
  author={Alizadeh, Negar and Castor, Fernando},
  booktitle={Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering-Software Engineering for AI},
  pages={134--139},
  year={2024}
}

@inproceedings{nahrstedt2024empirical,
  title={An Empirical Study on the Energy Usage and Performance of Pandas and Polars Data Analysis Python Libraries},
  author={Nahrstedt, Felix and Karmouche, Mehdi and Bargie{\l}, Karolina and Banijamali, Pouyeh and Nalini Pradeep Kumar, Apoorva and Malavolta, Ivano},
  booktitle={Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
  pages={58--68},
  year={2024}
}

@inproceedings{strubell2020energy,
  title={Energy and policy considerations for modern deep learning research},
  author={Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={34},
  number={09},
  pages={13693--13696},
  year={2020}
}

@inproceedings{hollo2021statistical,
  title={Statistical Racing Crossover Based Genetic Algorithm for Vehicle Routing Problem},
  author={Holl{\'o}-Szab{\'o}, {\'A}kos and Albert, Istv{\'a}n and Botzheim, J{\'a}nos},
  booktitle={2021 IEEE 21st International Symposium on Computational Intelligence and Informatics (CINTI)},
  pages={000267--000272},
  year={2021},
  organization={IEEE}
}

@inproceedings{merelo2016ranking,
  title={Ranking the Performance of Compiled and Interpreted Languages in Genetic Algorithms},
  author={Merelo-Guerv{\'o}s, Juan Juli{\'a}n and Blancas-Alvarez, Israel and Castillo, Pedro A and Romero, Gustavo and Garc{\'\i}a-S{\'a}nchez, Pablo and Rivas, Victor M and Garc{\'\i}a-Valdez, Mario and Hern{\'a}ndez-{\'A}guila, Amaury and Rom{\'a}n, Mario},
  booktitle={Proceedings of the International Conference on Evolutionary Computation Theory and Applications, Porto, Portugal},
  volume={11},
  pages={164--170},
  year={2016}
}

@inproceedings{merelo2017ranking,
  title={Ranking programming languages for evolutionary algorithm operations},
  author={Merelo-Guerv{\'o}s, Juan-Juli{\'a}n and Blancas-{\'A}lvarez, Israel and Castillo, Pedro A and Romero, Gustavo and Garc{\'\i}a-S{\'a}nchez, Pablo and Rivas, V{\'\i}ctor M and Garc{\'\i}a-Valdez, Mario and Hern{\'a}ndez-{\'A}guila, Amaury and Rom{\'a}n, Mario},
  booktitle={Applications of Evolutionary Computation: 20th European Conference, EvoApplications 2017, Amsterdam, The Netherlands, April 19-21, 2017, Proceedings, Part I 20},
  pages={689--704},
  year={2017},
  organization={Springer}
}

@article{merelo2024best,
  title={Best practices for energy-thrifty evolutionary algorithms in the low-level language zig},
  author={Merelo Guervos, Juan Juli{\'a}n and Mora Garc{\'\i}a, Antonio Miguel and Garc{\'\i}a-Valdez, Mario and others},
  year={2024}
}

@inbook{Corne_2018,
   title={Evolutionary Algorithms},
   ISBN={9783319071534},
   url={http://dx.doi.org/10.1007/978-3-319-07153-4_27-1},
   DOI={10.1007/978-3-319-07153-4_27-1},
   booktitle={Handbook of Heuristics},
   publisher={Springer International Publishing},
   author={Corne, David and Lones, Michael A.},
   year={2018},
   pages={1â€“22} }

@inproceedings{novoa2021measuring,
  title={Measuring the Environmental Cost in the Evaluation of Metaheuristics},
  author={Novoa-Hern{\'a}ndez, Pavel and Puris, Amilkar and Pelta, David A},
  booktitle={19th World Congress of the International Fuzzy Systems Association (IFSA), 12th Conference of the European Society for Fuzzy Logic and Technology (EUSFLAT), and 11th International Summer School on Aggregation Operators (AGOP)},
  pages={203--210},
  year={2021},
  organization={Atlantis Press}
}

@inproceedings{DBLP:conf/icsoft/GuervosGC23,
  author       = {Juan Juli{\'{a}}n Merelo-Guerv{\'{o}}s and
                  Mario Garc{\'{\i}}a{-}Valdez and
                  Pedro A. Castillo},
  editor       = {Hans{-}Georg Fill and
                  Francisco Jos{\'{e}} Dom{\'{\i}}nguez Mayo and
                  Marten van Sinderen and
                  Leszek A. Maciaszek},
  title        = {An Analysis of Energy Consumption of {JavaScript} Interpreters with
                  Evolutionary Algorithm Workloads},
  booktitle    = {Proceedings of the 18th International Conference on Software Technologies,
                  {ICSOFT} 2023, Rome, Italy, July 10-12, 2023},
  pages        = {175--184},
  publisher    = {{SCITEPRESS}},
  year         = {2023},
  url          = {https://doi.org/10.5220/0012128100003538},
  doi          = {10.5220/0012128100003538},
  timestamp    = {Mon, 31 Jul 2023 15:40:15 +0200},
  biburl       = {https://dblp.org/rec/conf/icsoft/GuervosGC23.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{garg2023analyzing,
  title={Analyzing and Rating Greenness of Nature-Inspired Algorithms},
  author={Garg, Kanaishk and Jindal, Chander and Kumar, Shobhit and Juneja, Shallu},
  booktitle={6th International Conference on Innovative Computing and Communication (ICICC 2023)},
  year={2023}
}

@article{jamil2022analyzing,
  title={Analyzing energy consumption of nature-inspired optimization algorithms},
  author={Jamil, Mohammad Newaj and Kor, Ah-Lian},
  journal={Green Technology, Resilience, and Sustainability},
  volume={2},
  number={1},
  pages={1},
  year={2022},
  publisher={Springer}
}

@article{garcia2019estimation,
  title={Estimation of energy consumption in machine learning},
  author={Garc{\'\i}a-Mart{\'\i}n, Eva and Rodrigues, Crefeda Faviola and Riley, Graham and Grahn, H{\aa}kan},
  journal={Journal of Parallel and Distributed Computing},
  volume={134},
  pages={75--88},
  year={2019},
  publisher={Elsevier}
}


@InProceedings{10.1007/978-3-319-45823-6_51,
author="de Vega, F. Fern{\'a}ndez
and Ch{\'a}vez, F.
and D{\'i}az, J.
and Garc{\'i}a, J. A.
and Castillo, P. A.
and Merelo, Juan J.
and Cotta, C.",
editor="Handl, Julia
and Hart, Emma
and Lewis, Peter R.
and L{\'o}pez-Ib{\'a}{\~{n}}ez, Manuel
and Ochoa, Gabriela
and Paechter, Ben",
title="A Cross-Platform Assessment of Energy Consumption in Evolutionary Algorithms",
booktitle="Parallel Problem Solving from Nature -- PPSN XIV",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="548--557",
abstract="Energy consumption is a matter of paramount importance in nowadays environmentally conscious society. It is also bound to be a crucial issue in light of the emergent computational environments arising from the pervasive use of networked handheld devices and wearables. Evolutionary algorithms (EAs) are ideally suited for this kind of environments due to their intrinsic flexibility and adaptiveness, provided they operate on viable energy terms. In this work we analyze the energy requirements of EAs, and particularly one of their main flavours, genetic programming (GP), on several computational platforms and study the impact that parametrisation has on these requirements, paving the way for a future generation of energy-aware EAs. As experimentally demonstrated, handheld devices and tiny computer models mainly used for educational purposes may be the most energy efficient ones when looking for solutions by means of EAs.",
isbn="978-3-319-45823-6"
}


@inproceedings{fernandez2019,
	address = {Cham},
	author = {Fern{\'a}ndez de Vega, Francisco and D{\'\i}az, Josefa and Garc{\'\i}a, Juan {\'A}ngel and Ch{\'a}vez, Francisco and Alvarado, Jorge},
	booktitle = {Artificial Evolution},
	editor = {Idoumghar, Lhassane and Legrand, Pierrick and Liefooghe, Arnaud and Lutton, Evelyne and Monmarch{\'e}, Nicolas and Schoenauer, Marc},
	isbn = {978-3-030-45715-0},
	pages = {96--109},
	publisher = {Springer International Publishing},
	title = {Looking for Energy Efficient Genetic Algorithms},
	year = {2020}}

@article{diaz2022population,
  title={Population size influence on the energy consumption of genetic programming},
  author={D{\'\i}az-{\'A}lvarez, Josefa and Castillo, Pedro A and Fernandez de Vega, Francisco and Ch{\'a}vez, Francisco and Alvarado, Jorge},
  journal={Measurement and Control},
  volume={55},
  number={1-2},
  pages={102--115},
  year={2022},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{diaz2018fuzzy,
  title={A fuzzy rule-based system to predict energy consumption of genetic programming algorithms},
  author={Diaz Alvarez, Josefa and Castillo Mart{\'\i}nez, Pedro Angel and Rodr{\'\i}guez D{\'\i}az, Francisco Javier and Fern{\'a}ndez de Vega, Francisco and others},
  year={2018},
  publisher={ComSIS Consortium}
}


@article{abdelhafez2019component,
  title={A component-based study of energy consumption for sequential and parallel genetic algorithms},
  author={Abdelhafez, Amr and Alba, Enrique and Luque, Gabriel},
  journal={The Journal of Supercomputing},
  volume={75},
  pages={6194--6219},
  year={2019},
  publisher={Springer}
}

@CONFERENCE{Abdelhafez2019121,
	author = {Abdelhafez, Amr and Luque, Gabriel and Alba, Enrique},
	title = {Analyzing the Energy Consumption of Sequential and Parallel Metaheuristics},
	year = {2019},
	journal = {2019 International Conference on High Performance Computing and Simulation, HPCS 2019},
	pages = {121 â€“ 128},
	doi = {10.1109/HPCS48598.2019.9188170},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082862038&doi=10.1109%2fHPCS48598.2019.9188170&partnerID=40&md5=ae7d8024fe29aff62963b60aa5f12287},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}


@inproceedings{maryam2018evolutionary,
  title={Evolutionary algorithms in cloud computing from the perspective of energy consumption: A review},
  author={Maryam, Khola and Sardaraz, Muhammad and Tahir, Muhammed},
  booktitle={2018 14th international conference on emerging technologies (ICET)},
  pages={1--6},
  year={2018},
  organization={IEEE}
}

@article{verdecchia2023systematic,
  title={A Systematic Review of {Green AI}},
  author={Verdecchia, Roberto and Sallou, June and Cruz, Lu{\'\i}s},
  journal={arXiv preprint arXiv:2301.11047},
  year={2023}
}

@article{hidalgo2023sustainable,
  title={Sustainable Artificial Intelligence Systems: An Energy Efficiency Approach},
  author={Hidalgo, Ignacio and Fen{\'a}ndez-de\_Vega, Francisco and Ceberio, Josu and Garnica, Oscar and Velasco, J Manuel and Cort{\'e}s, Juan Carlos and Villanueva, Rafael and D{\'\i}az, Josefa},
  year={2023},
  publisher={TechRxiv}
}

@inproceedings{10.1145/3638530.3664093,
author = {Cotta, Carlos and Mart\'{\i}nez-Cruz, Jes\'{u}s},
title = {Energy Consumption Analysis of Batch Runs of Evolutionary Algorithms},
year = {2024},
isbn = {9798400704956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638530.3664093},
doi = {10.1145/3638530.3664093},
abstract = {We analyze the energy consumption of running evolutionary algorithms in batch as a function of the rest time between runs. It is shown that energy consumption can be reduced by 5\%-8\% by inserting short pauses between runs to reduce hysteretic phenomena.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {87â€“88},
numpages = {2},
keywords = {evolutionary algorithms, energy consumption, green AI, sustainable computing},
location = {Melbourne, VIC, Australia},
series = {GECCO '24 Companion}
}


@phdthesis{chang:phd,
author={Chang,Yangyang},
year={2023},
title={Design Approaches for Lightweight Machine Learning Models},
journal={ProQuest Dissertations and Theses},
pages={131},
note={Copyright - Database copyright ProQuest LLC; ProQuest does not claim copyright in the individual underlying works; Ãšltima actualizaciÃ³n - 2023-08-05},
abstract={In this era of data explosion, the diversity and complexity of data are gradually increasing. The corresponding data processing models become massive and complicated. Especially for dealing with high-dimensional data, large-size inputs, and low latency, modern machine learning methods (e.g., deep neural networks) require advanced hardware solutions (e.g., High Power Graphic Processing Units, Tensor Process Units). To run the models efficiently on embedded platforms, designs of lightweight machine learning are important to ensure small computation and memory requirements. This thesis shows six innovative designs of lightweight machine learning models. Specifically, the introduced designs include the quantized vision transformer, optimized binarized neural networks (BNNs), and lightweight convolutional neural networks (CNNs). For high- dimensional multitasking continuous and discrete optimizations, the innovative lightweight designs contain the modified multifactorial and cross-target evolutionary algorithms (EAs). For data compression, this thesis proposes a hybrid compressor for medical electrocardiogram (ECG) data on an embedded system. In future work, the overall lightweight design framework can be integrated by the proposed structures to include full-system compression, optimization, and quantization. Quantization using a small number of bits shows promise for reducing latency and memory usage in DNNs. However, most quantization methods cannot readily handle complicated functions such as exponential and square root, and prior approaches involve complex processes that must interact with floating-point calculations during the quantization pass. The proposed quantized vision transformer in this thesis provides a robust method for the full integer quantization of the vision transformer without requiring any intermediate floating-point computations. The quantization techniques can be applied in various hardware or software implementations, including processor/memory architectures and FPGAs. BNNs have shown promise in low-power embedded systems, but these are typically designed starting from existing architectures that are based on floating-point number representations. It is also hard to meet the classification requirements because the weights and activations are limited to Â±1. This thesis applies the efficient genetic algorithm (GA) to optimize a fully connected binarized architecture to increase the BNN performance without changing its basic operators. The simulation results demonstrate the effectiveness of the proposed method to improve the performance of BNNs. Novel design frameworks for lightweight CNNs are proposed for embedded system applications on image classification tasks. Scalable lightweight architectures for CNNs are first proposed. The population-based metaheuristic approaches of the genetic algorithm (GA), cuckoo search (CS), multifactorial evolutionary algorithm (MFEA), and a proposed hybrid evolutionary approach are then used to optimize the proposed CNN architectures. The proposed optimization process uses no assumptions (e.g., weight-sharing) or approximations (e.g., surrogate function). Two encoding methods are proposed related to the most critical computational parts of CNNs, and the metaheuristic approaches are compared for small population sizes. The results from these various metaheuristic approaches are evaluated using the metrics of computation time and classification accuracy. The final architecture obtained, which has a favorable tradeoff between the amount of computation and accuracy, is indicated. On a set of large-dimensional, multitasking, continuous optimization problems, multifactorial optimization has become one of the most promising paradigms for evolutionary multitasking within the field of computational intelligence. This thesis presents an in-depth analysis of this approach by considering several variations of the standard MFEA. By using a simpler structure together with some enhanced operators, two new MFEAs are proposed. In the approach presented, redundant hyperparameters are removed and the operators are simplified. Compared with the traditional MFEA, the proposed two MFEAs produce better results and are suitable for an embedded system implementation. To handle both non-convex continuous and NP-hard discrete optimization problems, this thesis proposes the class algorithm, a new type of evolutionary algorithm. The methodology is inspired by the concepts of division of labor and specialization. Individuals form subpopulations of different classes, and each class has its own characteristics. The entire population evolves through influences among individuals within and between the different subpopulations. The performance of the class algorithm surpasses other evolutionary algorithms for many test functions of single-objective continuous optimization benchmark problems. Compared with mature application software, the class algorithm also shows a competent ability to solve large-scale discrete optimization problems. The computation time is only 0.48 or 0.36 of published GA results when the class algorithm run in series or parallel, respectively, and the class algorithm is very suitable for use either in embedded systems or on a traditional hardware platform. In summary, compared with traditional EAs, the class algorithm not only has better performance but also has a smaller runtime. Cardiovascular diseases are the number one cause of death worldwide. Monitoring patients with heart disease can be done by analyzing the electrocardiogram. However, the large amount of data poses a burden for a system that is implemented as an embedded system with limited memory and computation capabilities. Traditionally, lossless compression methods have been favored to reduce the memory requirements due to the critical nature of the application. However, if the reconstruction of a lossy signal does not significantly affect the diagnosis capability, then those methods may become attractive due to their larger compression ratios. This thesis proposes a hybrid lossy/lossless compression system with good signal fidelity and compression ratio characteristics. The performance is evaluated after decompression using deep neural networks (DNNs) that have been shown to have good classification capabilities. For the CODE (Clinical Outcomes in Digital Electrocardiology) dataset, the proposed hybrid compressor can achieve an average compression ratio of 5.18 with a mean squared error of 0.20, and DNN-based diagnoses of the decompressed waveforms have, on average, only 0.8 additional erroneous diagnoses out of a total of 402 cases compared to using the original ECG data. For the PTB-XL dataset, the hybrid compressor can achieve a high average compression ratio of 4.91 with a mean squared error of 0.01. In addition, the decompressed ECGs have only a 2.46% lower macro averaged area under the receiver operating characteristic curve (AUC) score than when using the original ECGs.},
keywords={Convolutional neural networks; Evolutionary algorithm; Medical electrocardiogram; Network architecture; Machine learning; Computer science; Electrical engineering; Artificial intelligence; 0544:Electrical engineering; 0800:Artificial intelligence; 0984:Computer science},
isbn={9798379926724},
language={English},
url={https://www.proquest.com/dissertations-theses/design-approaches-lightweight-machine-learning/docview/2840872796/se-2},
}

@article{aquino2024energy,
  title={Energy Efficiency Evaluation of Frameworks for Algorithms in Time Series Forecasting},
  author={Aquino-Br{\'\i}tez, Sergio and Garc{\'\i}a-S{\'a}nchez, Pablo and Ortiz, Andr{\'e}s and Aquino-Br{\'\i}tez, Diego},
  journal={Engineering Proceedings},
  volume={68},
  number={1},
  pages={30},
  year={2024},
  publisher={MDPI}
}
